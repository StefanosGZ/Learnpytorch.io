{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3757584ca514e62b58003a1b5a2a016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aae7d704e6c844ce80b4b89fec909d2b",
              "IPY_MODEL_0d6c0b78b06d4f4fa0548ca213195171",
              "IPY_MODEL_c205c4f8dcbd432b96a5fdcf1b45fe8c"
            ],
            "layout": "IPY_MODEL_689e38133d7846138c11c3de21b0e5e0"
          }
        },
        "aae7d704e6c844ce80b4b89fec909d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b50cdee60ed94ddea5f819ea5b7b76b9",
            "placeholder": "​",
            "style": "IPY_MODEL_3662958a3dd0465cb2ecfc7e8bd1d5b0",
            "value": "  0%"
          }
        },
        "0d6c0b78b06d4f4fa0548ca213195171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba5dd46f3ff84337a1d8baf60de5b200",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4e73359534a4d43a89209e70d312e92",
            "value": 0
          }
        },
        "c205c4f8dcbd432b96a5fdcf1b45fe8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afd2d9e185234c9baf238e9593fe3464",
            "placeholder": "​",
            "style": "IPY_MODEL_121d40a40f4547e887425d1f1dd60566",
            "value": " 0/5 [00:57&lt;?, ?it/s]"
          }
        },
        "689e38133d7846138c11c3de21b0e5e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b50cdee60ed94ddea5f819ea5b7b76b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3662958a3dd0465cb2ecfc7e8bd1d5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba5dd46f3ff84337a1d8baf60de5b200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4e73359534a4d43a89209e70d312e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afd2d9e185234c9baf238e9593fe3464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "121d40a40f4547e887425d1f1dd60566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StefanosGZ/Learnpytorch.io/blob/main/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "5fcba5c8-524e-4fed-98e9-2c8dee312db9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "04344ce4-311d-4ec8-b708-eaa86ff981e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Image classification\n",
        "2. Detecting (Videos)\n",
        "3. Self-driving cars"
      ],
      "metadata": {
        "id": "5aCH3n6eSSaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting in machine learning occurs when a model learns the training data too well, capturing noise and details to the extent that it negatively impacts the performance on new, unseen data."
      ],
      "metadata": {
        "id": "cPNIw7-gS79z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Cross-validation: This technique involves dividing the dataset into multiple parts, using some for training and the rest for validation. It helps ensure that the model performs well on unseen data.\n",
        "2. Regularization: Methods like Ridge and Lasso add a penalty for larger coefficients in the model, which can reduce overfitting by preventing the model from becoming too complex.\n",
        "3. Early Stopping: This is a form of regularization where you stop training before the model has a chance to overfit. Monitoring the validation loss and stopping when it begins to increase can prevent overfitting."
      ],
      "metadata": {
        "id": "s9JUxSnOTCbr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Done"
      ],
      "metadata": {
        "id": "BWdxF_OsTevy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "train_data = MNIST(root = 'data',\n",
        "                   train = True,\n",
        "                   download = True,\n",
        "                   transform = ToTensor(),\n",
        "                   target_transform = None)\n",
        "test_data = MNIST(root = 'data',\n",
        "                  train = False,\n",
        "                  download = True,\n",
        "                  transform = ToTensor(),\n",
        "                  target_transform = False)\n",
        "\n",
        "train_data, test_data"
      ],
      "metadata": {
        "id": "SHjeuN81bHza",
        "outputId": "65de5683-90d3-4678-adb2-b4ae807ae208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset MNIST\n",
              "     Number of datapoints: 60000\n",
              "     Root location: data\n",
              "     Split: Train\n",
              "     StandardTransform\n",
              " Transform: ToTensor(),\n",
              " Dataset MNIST\n",
              "     Number of datapoints: 10000\n",
              "     Root location: data\n",
              "     Split: Test\n",
              "     StandardTransform\n",
              " Transform: ToTensor()\n",
              " Target transform: False)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols = 3,3\n",
        "\n",
        "for i in range(1,rows*cols+1):\n",
        "  img = train_data[i][0]\n",
        "  img = img.squeeze()\n",
        "\n",
        "  label = train_data[i][1]\n",
        "  fig.add_subplot(rows,cols,i)\n",
        "  plt.imshow(img, cmap='gray')\n",
        "  plt.title(label)\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE",
        "outputId": "7f1caeb7-9be0-4cb4-9af9-73774311b904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x900 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    dataset = train_data,\n",
        "    batch_size = 32,\n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    dataset = test_data,\n",
        "    batch_size = 32,\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class MNISTV0(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = input_shape,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = hidden_units,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2)\n",
        "    )\n",
        "\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = hidden_units,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = hidden_units,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 1,\n",
        "                  padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2)\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = hidden_units * 7 * 7,\n",
        "                  out_features = output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    x = self.conv_block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "model = MNISTV0(input_shape = 1,\n",
        "                hidden_units = 10,\n",
        "                output_shape = 10).to(device)"
      ],
      "metadata": {
        "id": "5IKNF22XbKYS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device = device):\n",
        "\n",
        "  model.train()\n",
        "  train_loss = 0\n",
        "  model.to(device)\n",
        "  for batch, (X,y) in enumerate(data_loader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "  train_loss /= len(data_loader)\n",
        "  print(f\"Train loss: {train_loss:.3f}\")"
      ],
      "metadata": {
        "id": "ZVFLhZCyYkzj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device = device):\n",
        "  test_loss = 0\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in data_loader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      test_pred = model(X)\n",
        "\n",
        "      loss = loss_fn(test_pred, y)\n",
        "      test_loss += loss\n",
        "\n",
        "    test_loss /= len(data_loader)\n",
        "    print(f'Test loss: {test_loss:.3f}')"
      ],
      "metadata": {
        "id": "F8qSvoMlZPPZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(),\n",
        "                             lr = 0.1)"
      ],
      "metadata": {
        "id": "A_5_UtWtcENt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "cpu_start = timer()\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f'Epoch: {epoch}\\n-----')\n",
        "  train_step(model = model,\n",
        "             data_loader = train_dataloader,\n",
        "             loss_fn = loss_fn,\n",
        "             optimizer = optimizer,\n",
        "             device = 'cpu')\n",
        "  test_step(model = model,\n",
        "            data_loader = test_dataloader,\n",
        "            loss_fn = loss_fn,\n",
        "            device = 'cpu')\n",
        "\n",
        "cpu_end = timer()\n",
        "\n",
        "print(f\"Total training time is: {cpu_end - cpu_start:.2f}\")"
      ],
      "metadata": {
        "id": "xz1RraJlZPM5",
        "outputId": "dbd6f2b6-edf0-40dd-8a23-5ad052ecc032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "c3757584ca514e62b58003a1b5a2a016",
            "aae7d704e6c844ce80b4b89fec909d2b",
            "0d6c0b78b06d4f4fa0548ca213195171",
            "c205c4f8dcbd432b96a5fdcf1b45fe8c",
            "689e38133d7846138c11c3de21b0e5e0",
            "b50cdee60ed94ddea5f819ea5b7b76b9",
            "3662958a3dd0465cb2ecfc7e8bd1d5b0",
            "ba5dd46f3ff84337a1d8baf60de5b200",
            "a4e73359534a4d43a89209e70d312e92",
            "afd2d9e185234c9baf238e9593fe3464",
            "121d40a40f4547e887425d1f1dd60566"
          ]
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3757584ca514e62b58003a1b5a2a016"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 0\n",
            "-----\n",
            "Train loss: 2.313\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'bool' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-0ae24af9ee30>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m              \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m              device = 'cpu')\n\u001b[0;32m---> 11\u001b[0;31m   test_step(model = model,\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-53817ce6b5aa>\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(model, data_loader, loss_fn, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "cpu_start = timer()\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f'Epochs: {epoch}\\n-----')\n",
        "  train_step(model = model,\n",
        "             data_loader = train_dataloader,\n",
        "             loss_fn = loss_fn,\n",
        "             optimizer = optimizer,\n",
        "             device = device)\n",
        "  test_step(model = model,\n",
        "            data_loader = test_dataloader,\n",
        "            loss_fn = loss_fn,\n",
        "            device = device)\n",
        "\n",
        "cpu_end = timer()\n",
        "\n",
        "print(f\"Total training time is: {cpu_end - cpu_start:.2f}\")"
      ],
      "metadata": {
        "id": "aWb7-VUZYkvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}